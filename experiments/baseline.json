{
    "batch_size": 32,
    "n_epoch": 10,
    "T": 2,
    "model": {
        "num_hidden_layers": 12,
        "num_attention_heads": 8,
        "hidden_size": 512,
        "intermediate_size": 1024
    },
    "optimizer": {
        "lr": 0.0005,
        "betas": [
            0.9,
            0.95
        ],
        "eps": 0.00001,
        "weight_decay": 0.1
    }
}